{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01080169",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36388626",
   "metadata": {},
   "source": [
    "# Relevance By Task - Results\n",
    "\n",
    "The goal here is to analyze the results achieved by the differents types of tasks with the aim to find the tasks that could answer better for variation of context\n",
    "\n",
    "**Setup**\n",
    "\n",
    "The experiment setup was definided by computing the pass@1 and normalized sum of tests for five different samples in 27 different tasks with context window of 4 documents. For a task to be qualified it was necessary to have at leats five different samples (test sample + context). The difficulty was trunked in MEDIUM and three different contexts were used: No Context, Full Problem and Only Solution\n",
    "\n",
    "**Results**\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670351e0",
   "metadata": {},
   "source": [
    "## Summary\n",
    "- Load Data (Results + TACO Dataset)\n",
    "- Difference in results between contexts for each task\n",
    "- Further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c5ee219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4ee55e",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dd6a25a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>difficulty</th><th>tags</th><th>input</th></tr><tr><td>u32</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>14</td><td>&quot;MEDIUM&quot;</td><td>&quot;String algorithms&quot;</td><td>&quot;Given a string &#x27;s&#x27;. The task i…</td></tr><tr><td>14</td><td>&quot;MEDIUM&quot;</td><td>&quot;Data structures&quot;</td><td>&quot;Given a string &#x27;s&#x27;. The task i…</td></tr><tr><td>14</td><td>&quot;MEDIUM&quot;</td><td>&quot;Amortized analysis&quot;</td><td>&quot;Given a string &#x27;s&#x27;. The task i…</td></tr><tr><td>22</td><td>&quot;MEDIUM&quot;</td><td>&quot;Tree algorithms&quot;</td><td>&quot;Given an array arr[] which con…</td></tr><tr><td>22</td><td>&quot;MEDIUM&quot;</td><td>&quot;Sorting&quot;</td><td>&quot;Given an array arr[] which con…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 4)\n",
       "┌─────┬────────────┬────────────────────┬─────────────────────────────────┐\n",
       "│ id  ┆ difficulty ┆ tags               ┆ input                           │\n",
       "│ --- ┆ ---        ┆ ---                ┆ ---                             │\n",
       "│ u32 ┆ str        ┆ str                ┆ str                             │\n",
       "╞═════╪════════════╪════════════════════╪═════════════════════════════════╡\n",
       "│ 14  ┆ MEDIUM     ┆ String algorithms  ┆ Given a string 's'. The task i… │\n",
       "│ 14  ┆ MEDIUM     ┆ Data structures    ┆ Given a string 's'. The task i… │\n",
       "│ 14  ┆ MEDIUM     ┆ Amortized analysis ┆ Given a string 's'. The task i… │\n",
       "│ 22  ┆ MEDIUM     ┆ Tree algorithms    ┆ Given an array arr[] which con… │\n",
       "│ 22  ┆ MEDIUM     ┆ Sorting            ┆ Given an array arr[] which con… │\n",
       "└─────┴────────────┴────────────────────┴─────────────────────────────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "PATH = \"../data/TACO/processed\"\n",
    "\n",
    "train = (\n",
    "    pl.read_ipc(f\"{PATH}/train.feather\")\n",
    ")\n",
    "\n",
    "_filter = (\n",
    "        train\n",
    "        .filter(pl.col(\"difficulty\") == \"MEDIUM\")\n",
    "        .group_by(\"tags\")\n",
    "        .agg(pl.col(\"id\").count().alias(\"count\"))\n",
    "        .filter(pl.col(\"count\") >= 6)\n",
    "        .select(\"tags\")\n",
    "\n",
    "    )\n",
    "\n",
    "df = (\n",
    "        train\n",
    "        .filter(pl.col(\"difficulty\") == \"MEDIUM\")\n",
    "        .join(_filter, on=\"tags\", how=\"inner\")\n",
    "        )\n",
    "\n",
    "df.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2719effe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.select(\"tags\").unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f551059",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
